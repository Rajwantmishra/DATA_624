---
title: "DAta 624 Group3 Project 2"
author: "Jeff Littlejohn"
date: "7/5/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(psych)
library(DataExplorer)
library(GGally)
```

## Introduction

As most of us know, ensuring our beverages are produced at the correct potential for hydrogen (pH) level is an essential driver to our business. This pH score, the measure of acidity and alkalinity in our liquids, must be within a narrow, critical range to ensure long-term sales.

The objective of this project is to consider a number of measures and data points involved in the production of our beverages and build a model to use those factors to be able to predict the pH level of the beverage. 

Note that a factor being highly predictive of an outcome does not necessarily mean that the factor caused the outcome. For example, beverages that end up with higher than desired pH levels may also show high bowl setpoints. This does not mean that high bowl setpoints cause excessive pH values. They might both be similarly affected by an unknown cause, or large pH values may cause the high bowl setpoints. Our goal is simply to build a model that predicts pH levels. This process may lead to insights about possible causes of pH level problems, but that outcome is certainly not a given.

To construct this model, we had to first understand our data. We have more than 2800 production records of beverages that feature 33 data points, including Brand Code, Fill Ounces, PSC CO2, Temperature, etc. A full list of data elements will be conveyed in the next section. Some of the production records do not have values for all data elements, which is an obstacle we will had to overcome in building our model using established statistical principles. We also had to review

Data scientists use different methods to build models. No one approach gives the optimal approach for all data sets - and their underlying processes. To predict pH, we started by using linear regression, which constructs equations that look similar to you might have experienced in algebra at school. Next, we saw how effective nonlinear regression approaches such as neural networks and support vector machines (SVMs) are in predicting pH. Finally, we attempted to build models that use regression trees and rule-based models.

Don't be overwhelmed by mathematical terminology. We - or, rather our computers - are just using different methods to take the 33 different data elements and trying to use them to figure out their relationship to pH levels in our beverages.

```{r cars}
summary(cars)
```

## Approach

1. Exploratory Data Analysis
2. Data Processing
3. Linear Regression
4. Nonlinear Regression
5. Regression Trees and Rule-Based Models
6. Conclusion

## Exploratory Data Analysis

### Data Loading

```{r}
bev_train <- readxl::read_excel('StudentData_TO_MODEL.xlsx',col_names = TRUE, sheet = 'Subset')
bev_test <- readxl::read_excel('StudentEvaluation_TO_PREDICT.xlsx',col_names = TRUE, sheet = 'Subset (2)')
```


```{r}
str(bev_train)
```

We have 33 data elements for 2571 records that will be used for training. We expect some missing or NULL values - here we see them reflected in the "NA" values in the "Hyd Pressure 2" measurements.

Here, we verify that our test data contains the same elements.

```{r}
dim(bev_test)
```

As mentioned above, we will generate the model on using the training data set that covers 2571 rows and then evaluate its accuracy - and other metrics - using the 267-record test data set.

### Data Exploration

Next, we explore our data using summary statistics.

```{r}
describe(bev_train)
```

Brand Code is a string (non-numeric) field, so its lack of a mean makes sense. We see a wide range of values. Some may be on different scales. Despite being mostly numeric fields, some of these might use temperatures in Celsius, whereas others like Carb[onation] Pressure use pounds per square inch. In order to build the most effective predictive model, we may apply data transformations to standardize these numeric data elements.

```{r}
plot_histogram(bev_train, ggtheme=theme_light())
```

Note that the scales of the x-axes vary for each element. Nonetheless, we see data elements with normal distributions and many with likely outliers. Some histograms reveal bimodal or even trimodal distributions.

Here, we take a closer look at the pH values present in our training data.

```{r,warning=FALSE}
ggplot(bev_train, aes(PH)) + geom_histogram(bins=20) + theme_classic()
```

A slight left skew is evident, as is a right potential outlier.

Finally, a count of missing (NA) values by variable is conducted.

```{r}
plot_missing(bev_train, title = "Beverage Training Data: % Missing Values by Data Element")
```

MFR is missing for more than eight percent of our training records, and Brand Code is NA for almost five percent of them. Those will need to be handled in our next section.

Perhaps the most conceptually difficult aspect of data exploration in predictive modeling is checking for correlation. If two different variables reliably occur together, they can negatively affect our model. They tend to change in unison, and it becomes very difficult for the model to estimate the relationship between the two (or more) correlated independent variables and the dependent variable. If this sounds tricky - don't worry. In short, if we wanted to predict if it rained, we probably wouldn't want to include both 1) is the road wet and 2) whether or not drivers were using windshield wipers. One would give us the information contained within the others.

The correlations between variables in our training dataset are below.

```{r,warning=FALSE}
ggcorr(bev_train, label_size=3, nbreaks=5, geom = "text", hjst = 1)
```

```{r}
ggpairs(bev_train)
```


```{r}
corrplot(bev_train)
```


### Data Processing

```{r}

```

## References

https://readxl.tidyverse.org/

https://www.rdocumentation.org/packages/DataExplorer/versions/0.8.1/topics/plot_missing

https://datascience.stackexchange.com/questions/24452/in-supervised-learning-why-is-it-bad-to-have-correlated-features#:~:text=The%20stronger%20the%20correlation%2C%20the,tend%20to%20change%20in%20unison.